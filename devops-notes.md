## DockerfileğŸ³

```dockerfile
#1
FROM golang:1.22.5-alpine

#2
WORKDIR /journey

#3Âº
COPY go.mod go.sum ./

RUN go mod download && go mod verify

#4Âº
COPY . .

#5Âº
#WORKDIR /outrodir/app

#6Âº
RUN go build -o ./bin/journey .

#7Âº
EXPOSE 8080

#8Âº
ENTRYPOINT [ "/journey/bin/journey" ]
```

**1Âº** - FROM Ã© qual Ã© a linguagem que utilizamos no container que vamos criar, "de onde vamos partir", ele busca no dockerhub.
<br/> - Sempre utilizar uma tag de versÃ£o especÃ­fica, olhar se tem muitos CVE's na versÃ£o escolhida.
<br/> - Priorizar versÃ£o alpine, que Ã© menor/mais enxuta, possui uma superfÃ­cie de ataque menor.

**2Âº** - DiretÃ³rio de trabalho, se nÃ£o definido, Ã© adotado o diretÃ³rio raiz, que nÃ£o Ã© uma boa prÃ¡tica. Ele cria a pasta com o nome definido.

**3Âº** - Copiando os arquivos do projeto go.mod e go.sum responsÃ¡veis por gerenciar as dependÃªncias do projeto, para dentro do container, jogando na raiz da nossa pasta `journey`.
<br> - Tendo os dois arquivos, vamos conseguir executar o comando que realiza esse processo. Para executar comandos no dockerfile utilizamos o comando **RUN**.

**4Âº** - ApÃ³s instalarmos todas as dependÃªncias, precisamos buildar nossa aplicaÃ§Ã£o, porÃ©m nossos dados ainda nÃ£o estÃ£o dentro do container, para jogar tudo que temos no nosso projeto para o container, utilizamos o comando **COPY**, onde o primeiro `.` Ã© para pegar tudo que temos na raiz do nosso projeto, e o segundo `.` jogar para dentro da raiz do docker, nesse caso no nosso WORKDIR /journey.

**5Âº** - Ã‰ possÃ­vel mudar de diretÃ³rio a qualquer momento.

**6Âº** - Executando o comando de build, onde o `-o` define o output, por ser um binÃ¡rio vamos definir que ele vai ser gerado e adicionado na pasta /bin/journey, lembrando que o caminho `./bin/journey` sim precisa do `.`, pois ele faz referÃªncia ao diretÃ³rio local(journey), e o segundo parÃ¢metro Ã© o `.` que faz referÃªncia ao arquivo .go que precisa ser buildado, no caso journey.go.

**7Âº** - A porta que serÃ¡ exposta pelo container, no caso a 8080 por ser onde nossa aplicaÃ§Ã£o Ã© executada, se nÃ£o expormos a porta, a aplicaÃ§Ã£o vai executar sem ser possÃ­vel acessar.

**8Âº** - Entrypoint Ã© o que esse container vai executar, qual o caminho do executÃ¡vel da aplicaÃ§Ã£o que desejamos executar no container.

---

## Buildando dockerfileğŸ—

Comando docker para criar imagem
```
docker build -t api-journey:v1 .
```

Podemos listar as imagens
```
docker image ls ou docker images
```

Executar a criaÃ§Ã£o do nosso container
```
docker run --name api-journey -d -p 8080:8080 api-journey:v1
```
> Comando `-d` Ã© para rodar o container detached do terminal.

Verificar os containers rodando
```
docker ps -a
```

Se nosso container nÃ£o estiver rodando, podemos ver seu log utilizando o container ID
```
docker logs 514aa176536b
```

---

## Multi-Stage buildâœ¨

Podemos ver que o tamanho da nossa imagem criada estÃ¡ bem alto, muito do que temos em nossa imagem sÃ£o arquivos do nosso projeto, porÃ©m, no final do dia, sÃ³ precisamos do binÃ¡rio.

Temos uma imagem de API simples com quase 600MB de espaÃ§o.

![tamanho-imagem-v1](https://github.com/user-attachments/assets/10d296fb-f1b7-4ed7-bd09-641d827c926d)

Para resolver isso podemos alterar nosso dockerfile para ter vÃ¡rias etapas, como build e execuÃ§Ã£o.

```dockerfile
#1Âº
FROM golang:1.22.5-alpine as builder

WORKDIR /app

COPY go.mod go.sum ./

RUN go mod download && go mod verify

COPY . .

RUN go build -o /bin/journey .

#2Âº
FROM scratch

WORKDIR /app

#3Âº
COPY --from=builder /bin/journey .

EXPOSE 8080

ENTRYPOINT [ "./journey" ]
```

**1Âº** - Demos um alias a nosso processo, tudo que tiver de operaÃ§Ãµes atÃ© o prÃ³ximo `FROM` eu estou chamando de `builder`.

**2Âº** - Nesse segundo estÃ¡gio, inicio nosso container com base no [scratch](https://hub.docker.com/_/scratch), uma imagem docker que tem apenas o bÃ¡sico para um sistema ser executado.

**3Âº** - Conseguimos se comunicar entre estÃ¡gios, onde copiamos o que tem disponÃ­vel em /bin/journey do estÃ¡gio `builder` e colamos na raiz do nosso novo estÃ¡gio.

ApÃ³s essa alteraÃ§Ã£o, podemos criar nossa imagem novamente e visualizarmos se houve alteraÃ§Ã£o no tamanho de nossa imagem.

![tamanho-imagem-v2](https://github.com/user-attachments/assets/d137bb58-96c3-4b16-8950-49d026535bff)

Tivemos uma diminuiÃ§Ã£o de 96.95% no tamanho da nossa imagem.

---

## CI com github actions

Ã‰ possÃ­vel criar esse arquivo pelo github, mas caso queiramos criar a pasta e o arquivo `.github/workflows/main.yml` tambÃ©m Ã© possÃ­vel.

```yaml
#1Âº
name: CI

#2Âº
on:
  push:
    branches:
      - master

#3Âº
jobs:
  #4Âº  
  build-and-push:
    name: "Build and Push"
    runs-on:  ubuntu-latest

    #5Âº
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Build docker image
        run: docker build -t sandrolax/api-journey:latest .

```

**1Âº** - Nome do nosso workflow

**2Âº** - Define quando Ã© trigado nosos workflow, no caso, quando houver um push na branch master.

**3Âº** - O job Ã© uma mÃ¡quina em execuÃ§Ã£o e essa mÃ¡quina tem vÃ¡rios steps, podemos definir vÃ¡rios jobs com vÃ¡rios steps(teste/build/etc).

**4Âº** - Nome do meu job e onde ele vai ser executado.

**5Âº** - Steps sÃ£o os passos que desejo realizar quando o job processar, no nosso caso fazemos o `Checkout` que Ã© um [actions](https://github.com/actions/checkout)(steps prÃ©-prontos) que basicamente Ã© um check out da branch no workspace, apÃ³s isso realizamos o step de buildar a imagem da nossa api.

Como o objetivo Ã© em breve enviar para o container registry do dockerhub, precisamos colocar o nosso nome de usuÃ¡rio do dockerhub na frente do nome da imagem.

---

### Melhorias na action

**Gerar TAG imagem com base hash do commit**: Para isso criamos um step anterior a criaÃ§Ã£o da imagem e utilizando a vÃ¡riavel $GITHUB_SHA que estÃ¡ presente no contexto, tempos acesso ao hash, apÃ³s isso pegamos os 7 primeiros caracteres.

step:
```yaml
- name: Generate SHA
  id: generate_sha
  run: |
    SHA=$(echo $GITHUB_SHA | head -c7)
    echo "sha=$SHA" >> $GITHUB_OUTPUT
```

* Id para identificar os valores criados nesse passo.
* O pipe Ã© utilizado para definirmos comandos que tenham mais de uma linha.
* SHA recebe os 7 primeiros caracteres do hash do commit
* Criamos uma variÃ¡vel para adicionar o valor de SHA no output desse step. Todo step tem o output do anterior, uma maneira centralizada de ir passando informaÃ§Ãµes entre os steps.

ApÃ³s criado e adicionado na variÃ¡vel `GITHUB_OUTPUT`, podemos utilizar para definir a tag da criaÃ§Ã£o da nossa imagem. Abaixo temos um exemplo de como acessar esse valor no step de build.

```yaml
- name: Build docker image
  run: docker build -t sandrolax/api-journey:${{ steps.generate_sha.outputs.sha }} .
```

**Login no container registry**: Para fazer isso, vamos utilizar o action [Docker Login](https://github.com/marketplace/actions/docker-login), nele precisamos passar o usuÃ¡rio e senha(token) do registry que vamos utilizar.

Utilizando o DockerHub passo o nome do meu user e o token Ã© gerado no dockerhub em Account settings > Security > New Access Token.

Para utilizar essas informaÃ§Ãµes, como uma boa prÃ¡tica, vamos utilizar os secrects do github para setar os dados, isso estÃ¡ disponÃ­vel em Settings(Do repositÃ³rio) > Security > Actions > New Repository secret.

Abaixo o step criado:
```yaml
- name: Login to Docker Hub
  uses: docker/login-action@v3
  with:
    username: ${{ secrets.DOCKERHUB_USERNAME }}
    password: ${{ secrets.DOCKERHUB_TOKEN }}
```

**Enviando imagem para container registry**: Criamos o step e adicionamos o docker push, comando que envia a imagem criada para o dockerhub. Quanto Ã  tag podemos defini-la utilizando o comando docker tag.

Step criado:
```yaml
- name: Push to registry
  run: | 
    docker push sandrolax/api-journey:${{ steps.generate_sha.outputs.sha }}
    docker tag sandrolax/api-journey:${{ steps.generate_sha.outputs.sha }} sandrolax/api-journey:latest
    docker push sandrolax/api-journey:latest
```
> Boa prÃ¡tica

**Utilizando action para realizar o build e push**: O que fizemos manualmente atÃ© o momento funciona, porÃ©m, nÃ£o Ã© a melhor prÃ¡tica e estÃ¡ bem verboso. Vamos utilizar a [action ](https://github.com/marketplace/actions/build-and-push-docker-images) para melhorar essa parte do nosso workflow.

Revisando, ficarÃ¡ da seguinte forma:
```yaml
- name: Build and push
  uses: docker/build-push-action@v6
  with:
    context: .
    push: true
    tags: |
    sandrolax/api-journey:${{ steps.generate_sha.outputs.sha }}
    sandrolax/api-journey:latest
```

**Steps adicionais**: Poderiamos adicionar tambÃ©m um step para realizar os testes unitÃ¡rios, para isso Ã© necessÃ¡rio ter o go na mÃ¡quina onde roda o job, entÃ£o precisamos instalar o go e entÃ£o rodar os testes unitÃ¡rios.

Exemplo abaixo:
```
- name: Setup Go
uses: actions/setup-go@v5
with:
    go-version: "1.22.5"

- name: Run tests
run: go test
```

---

## Kubernetesâš“

### Arquitetura kube

![Components of kube](https://kubernetes.io/images/docs/components-of-kubernetes.svg)

**Node**: SÃ£o os componentes de trabalho, os nÃ³s se comunicam com o control plane atravÃ©s do kubelet e tem uma camada de rede que Ã© o kube-proxy. Conceitos como deployment, pod, deamonSet, service, ingress estÃ£o nesse componente. Para mais informaÃ§Ãµes, consulte a [documentaÃ§Ã£o](https://kubernetes.io/docs/concepts/architecture/nodes/).
**Control Plane**: Ã‰ o que gerencia globalmente nosso cluster, componentes de rede, scheduler, api, etcd(banco chave valor).  Ã‰ o cara que, se cair, temos um baita problema. Para mais informaÃ§Ãµes, consulte a [documentaÃ§Ã£o](https://dockerlabs.collabnix.com/kubernetes/beginners/Kubernetes_Control_Plane.html).
**Scheduler**: Ã‰ quem tenta alocar nossa aplicaÃ§Ã£o em um determinado nÃ³. [DocumentaÃ§Ã£o](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/)

---

### Namespace

Ã‰ uma divisÃ£o lÃ³gica para garantir uma melhor organizaÃ§Ã£o na execuÃ§Ã£o dos nossos pods. [Mais detalhes](https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/namespace-v1/).

Criando via comand line:
```
kubectl create namespace journey
```

---

### Secret

SÃ£o objetos onde podemos adicionar dados sensÃ­veis, possuem uma estrutura chave/valor e encoda em base64 nossos segredos. Por nÃ£o ser uma estrutura que criptografa os dados, nÃ£o Ã© recomendada a utilizaÃ§Ã£o em produÃ§Ã£o. Para mais detalhes, acesse a [documentaÃ§Ã£o](https://kubernetes.io/docs/concepts/configuration/secret/).

Exemplo de secret:
```yaml
apiVersion: v1
kind: Service

metadata:
  name: journey-service
  labels:
    app: journey

spec:
  selector:
    app: journey
  type: ClusterIP
  ports:
    - name: journey-service
      port: 80
      targetPort: 8080
      protocol: TCP
```

Para aplicar o secret podemos utilizar o comando:
```
kubectl apply -f k8s/secret.yaml -n journey
```

> Realizar no diretÃ³rio que possui o yaml e definir o namespace

---

### Deployment

Ã‰ a forma declarativa de definir o funcionamento de um replicaset e seus respectivos pods. Nele podemos utilizar outros recursos criados em nosso cluster, como, por exemplo, os secrets. Para mais sobre, [documentaÃ§Ã£o](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/).

Exemplo deployment:
```yaml
apiVersion: apps/v1
kind: Deployment

metadata:
  name: journey-deployment
  labels:
    app: journey

spec:
  replicas: 5
  selector:
    matchLabels:
      app: journey
  template:
    metadata:
      labels:
        app: journey
    spec:
      containers:
        - name: api-journey
          image: sandrolax/api-journey:4388865
          env:
            - name: JOURNEY_DATABASE_USER
              valueFrom:
                secretKeyRef:
                  name: db-connection
                  key: db_user
            - name: JOURNEY_DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-connection
                  key: db_password
            - name: JOURNEY_DATABASE_HOST
              valueFrom:
                secretKeyRef:
                  name: db-connection
                  key: db_host
            - name: JOURNEY_DATABASE_PORT
              valueFrom:
                secretKeyRef:
                  name: db-connection
                  key: db_port
            - name: JOURNEY_DATABASE_NAME
              valueFrom:
                secretKeyRef:
                  name: db-connection
                  key: db_name
          ports:
            - containerPort: 8080
          resources: 
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 128Mi
```

Para aplicar Ã© similar a secret:
```
kubectl apply -f k8s -n journey
```

> Por padrÃ£o, ele busca o arquivo deployment na pasta e o executa.

---

### Service

Ã‰ uma maneira de expor a rede do cluster, para conseguirmos acessar a aplicaÃ§Ã£o que estÃ¡ nos pods, na confirguraÃ§Ã£o do service precisamos definir como irÃ¡ funcionar a rede interna deles, apÃ³s isso realizar um [port-forward](https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/) para externalizar a rede interna para o da mÃ¡quina que executa o k8s. DocumentaÃ§Ã£o sobre [service](https://kubernetes.io/docs/concepts/services-networking/service/).

Exemplo de service:
```yaml
apiVersion: v1
kind: Service

metadata:
  name: journey-service
  labels:
    app: journey

spec:
  selector:
    app: journey
  type: ClusterIP
  ports:
    - name: journey-service
      port: 80
      targetPort: 8080
      protocol: TCP
```

Aplicando service:
```
kubectl apply -f k8s/service.yaml -n journey
```

Executando o port-forward:
```
kubectl port-forward svc/journey-service 8080:80 -n journey
```

> Sempre importante lembrar de passar o namespace na execuÃ§Ã£o dos comandos

Para mais informaÃ§Ãµes sobre o kube consultar o repositÃ³rio [study-k8s](https://github.com/Sandrolaxx/study-k8s) e tambÃ©m a [documentaÃ§Ã£o oficial](https://kubernetes.io/docs/home).